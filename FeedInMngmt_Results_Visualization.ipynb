{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load relevant Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the most important modules\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Results for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To assure that the result data is saved in the right format and directory to be visualized 2 dataframes are set up:\n",
    "- The first one will include all the predictions for each model for both the validation and the test set and for each timestep.\n",
    "- The second one will include all the actual observed values for each model for both the validation and the test set and for each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnnames = [\"date\",\"Step 1\",\"Step 2\",\"Step 3\",\"Step 4\",\"Step 5\",\"Step 6\",\"Step 7\",\"Step 8\",\"Step 9\",\n",
    "               \"Step 10\",\"Step 11\",\"Step 12\",\"Step 13\",\"Step 14\",\"Step 15\",\"Step 16\",\"Step 17\",\n",
    "               \"Step 18\", \"Model\", \"Dataset\"]\n",
    "\n",
    "# setting up source_pred\n",
    "df_pred = pd.read_csv(\"./Results/naive_shift_validation_predictions.csv\")\n",
    "df_naive_test_pred = pd.read_csv(\"./Results/naive_shift_test_predictions.csv\")\n",
    "df_expo_val_pred = pd.read_csv(\"./Results/exponential_smoothing_validation_predictions.csv\")\n",
    "df_expo_test_pred = pd.read_csv(\"./Results/exponential_smoothing_test_predictions.csv\")\n",
    "df_prophet_val_pred = pd.read_csv(\"./Results/prophet_validation_predictions.csv\")\n",
    "df_prophet_test_pred = pd.read_csv(\"./Results/prophet_test_predictions.csv\")\n",
    "df_multi_lstm_peephole_val_pred = pd.read_csv(\"./Results/multi_lstm_peephole_validation_predictions.csv\")\n",
    "df_multi_lstm_peephole_test_pred = pd.read_csv(\"./Results/multi_lstm_peephole_test_predictions.csv\")\n",
    "df_uni_lstm_peephole_val_pred = pd.read_csv(\"./Results/uni_lstm_peephole_validation_predictions.csv\")\n",
    "df_uni_lstm_peephole_test_pred = pd.read_csv(\"./Results/uni_lstm_peephole_test_predictions.csv\")\n",
    "df_multi_lstm_val_pred = pd.read_csv(\"./Results/multi_lstm_validation_predictions.csv\")\n",
    "df_multi_lstm_test_pred = pd.read_csv(\"./Results/multi_lstm_test_predictions.csv\")\n",
    "df_uni_lstm_val_pred = pd.read_csv(\"./Results/uni_lstm_validation_predictions.csv\")\n",
    "df_uni_lstm_test_pred = pd.read_csv(\"./Results/uni_lstm_test_predictions.csv\")\n",
    "\n",
    "# assuring coherence between the datasets\n",
    "df_expo_val_pred.drop(columns = [\"y_all_pred Step 19\",\"y_all_pred Step 20\"], inplace = True)\n",
    "df_expo_test_pred.drop(columns = [\"y_all_pred Step 19\",\"y_all_pred Step 20\"], inplace = True)\n",
    "df_prophet_val_pred.columns = df_pred.columns\n",
    "df_prophet_test_pred.columns = df_pred.columns\n",
    "df_multi_lstm_peephole_val_pred.columns = df_pred.columns\n",
    "df_multi_lstm_peephole_test_pred.columns = df_pred.columns\n",
    "df_uni_lstm_peephole_val_pred.columns = df_pred.columns\n",
    "df_uni_lstm_peephole_test_pred.columns = df_pred.columns\n",
    "df_multi_lstm_val_pred.columns = df_pred.columns\n",
    "df_multi_lstm_test_pred.columns = df_pred.columns\n",
    "df_uni_lstm_val_pred.columns = df_pred.columns\n",
    "df_uni_lstm_test_pred.columns = df_pred.columns\n",
    "df_multi_lstm_peephole_val_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_multi_lstm_peephole_test_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_uni_lstm_peephole_val_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_uni_lstm_peephole_test_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_multi_lstm_val_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_multi_lstm_test_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_uni_lstm_val_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_uni_lstm_test_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "\n",
    "# creating selectors for dataset variable\n",
    "df_pred[\"Dataset\"] = \"Validation\"\n",
    "df_naive_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_expo_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_expo_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_prophet_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_prophet_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_multi_lstm_peephole_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_multi_lstm_peephole_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_uni_lstm_peephole_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_uni_lstm_peephole_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_multi_lstm_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_multi_lstm_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_uni_lstm_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_uni_lstm_test_pred[\"Dataset\"] = \"Test\"\n",
    "\n",
    "\n",
    "# stacking all the predictions from the different models on the validation and test sets in one dataframe\n",
    "df_pred = df_pred.append(df_naive_test_pred,)\n",
    "df_pred = df_pred.append(df_expo_val_pred)\n",
    "df_pred = df_pred.append(df_expo_test_pred)\n",
    "df_pred = df_pred.append(df_prophet_val_pred)\n",
    "df_pred = df_pred.append(df_prophet_test_pred)\n",
    "df_pred = df_pred.append(df_multi_lstm_peephole_val_pred)\n",
    "df_pred = df_pred.append(df_multi_lstm_peephole_test_pred)\n",
    "df_pred = df_pred.append(df_uni_lstm_peephole_val_pred)\n",
    "df_pred = df_pred.append(df_uni_lstm_peephole_test_pred)\n",
    "df_pred = df_pred.append(df_multi_lstm_val_pred)\n",
    "df_pred = df_pred.append(df_multi_lstm_test_pred)\n",
    "df_pred = df_pred.append(df_uni_lstm_val_pred)\n",
    "df_pred = df_pred.append(df_uni_lstm_test_pred)\n",
    "df_pred.columns = columnnames\n",
    "df_pred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up source_test\n",
    "df_test = pd.read_csv(\"./Results/naive_shift_validation_values.csv\")\n",
    "df_naive_test_test = pd.read_csv(\"./Results/naive_shift_test_values.csv\")\n",
    "df_expo_val_test = pd.read_csv(\"./Results/exponential_smoothing_validation_values.csv\")\n",
    "df_expo_test_test = pd.read_csv(\"./Results/exponential_smoothing_test_values.csv\")\n",
    "df_prophet_val_test = pd.read_csv(\"./Results/prophet_validation_values.csv\")\n",
    "df_prophet_test_test = pd.read_csv(\"./Results/prophet_test_values.csv\")\n",
    "df_multi_lstm_peephole_val_test = pd.read_csv(\"./Results/multi_lstm_peephole_validation_values.csv\")\n",
    "df_multi_lstm_peephole_test_test = pd.read_csv(\"./Results/multi_lstm_peephole_test_values.csv\")\n",
    "df_uni_lstm_peephole_val_test = pd.read_csv(\"./Results/uni_lstm_peephole_validation_values.csv\")\n",
    "df_uni_lstm_peephole_test_test = pd.read_csv(\"./Results/uni_lstm_peephole_test_values.csv\")\n",
    "df_multi_lstm_val_test = pd.read_csv(\"./Results/multi_lstm_validation_values.csv\")\n",
    "df_multi_lstm_test_test = pd.read_csv(\"./Results/multi_lstm_test_values.csv\")\n",
    "df_uni_lstm_val_test = pd.read_csv(\"./Results/uni_lstm_validation_values.csv\")\n",
    "df_uni_lstm_test_test = pd.read_csv(\"./Results/uni_lstm_test_values.csv\")\n",
    "\n",
    "# assuring coherence between the datasets\n",
    "df_expo_val_test.drop(columns = [\"y_all_observed Step 1\",\"y_all_observed Step 2\"], inplace = True)\n",
    "df_expo_test_test.drop(columns = [\"y_all_observed Step 1\",\"y_all_observed Step 2\"], inplace = True)\n",
    "df_expo_val_test.columns = df_test.columns\n",
    "df_expo_test_test.columns = df_test.columns\n",
    "df_prophet_val_test.columns = df_test.columns\n",
    "df_prophet_test_test.columns = df_test.columns\n",
    "df_multi_lstm_peephole_val_test.columns = df_test.columns\n",
    "df_multi_lstm_peephole_test_test.columns = df_test.columns\n",
    "df_uni_lstm_peephole_val_test.columns = df_test.columns\n",
    "df_uni_lstm_peephole_test_test.columns = df_test.columns\n",
    "df_multi_lstm_val_test.columns = df_test.columns\n",
    "df_multi_lstm_test_test.columns = df_test.columns\n",
    "df_uni_lstm_val_test.columns = df_test.columns\n",
    "df_uni_lstm_test_test.columns = df_test.columns\n",
    "df_multi_lstm_peephole_val_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_multi_lstm_peephole_test_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_uni_lstm_peephole_val_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_uni_lstm_peephole_test_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_multi_lstm_val_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_multi_lstm_test_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_uni_lstm_val_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_uni_lstm_test_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "\n",
    "# creating selectors for dataset variable\n",
    "df_test[\"Dataset\"] = \"Validation\"\n",
    "df_naive_test_test[\"Dataset\"] = \"Test\"\n",
    "df_expo_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_expo_test_test[\"Dataset\"] = \"Test\"\n",
    "df_prophet_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_prophet_test_test[\"Dataset\"] = \"Test\"\n",
    "df_multi_lstm_peephole_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_multi_lstm_peephole_test_test[\"Dataset\"] = \"Test\"\n",
    "df_uni_lstm_peephole_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_uni_lstm_peephole_test_test[\"Dataset\"] = \"Test\"\n",
    "df_multi_lstm_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_multi_lstm_test_test[\"Dataset\"] = \"Test\"\n",
    "df_uni_lstm_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_uni_lstm_test_test[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# stacking all the actual values from the different models on the validation and test sets in one dataframe\n",
    "df_test = df_test.append(df_naive_test_test)\n",
    "df_test = df_test.append(df_expo_val_test)\n",
    "df_test = df_test.append(df_expo_test_test)\n",
    "df_test = df_test.append(df_prophet_val_test)\n",
    "df_test = df_test.append(df_prophet_test_test)\n",
    "df_test = df_test.append(df_multi_lstm_peephole_val_test)\n",
    "df_test = df_test.append(df_multi_lstm_peephole_test_test)\n",
    "df_test = df_test.append(df_uni_lstm_peephole_val_test)\n",
    "df_test = df_test.append(df_uni_lstm_peephole_test_test)\n",
    "df_test = df_test.append(df_multi_lstm_val_test)\n",
    "df_test = df_test.append(df_multi_lstm_test_test)\n",
    "df_test = df_test.append(df_uni_lstm_val_test)\n",
    "df_test = df_test.append(df_uni_lstm_test_test)\n",
    "\n",
    "df_test.columns = columnnames\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the Stacked Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both stacked dataframes are saved and can now be explored interactively via Bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"./Results/values.csv\", index = False)\n",
    "df_pred.to_csv(\"./Results/predictions.csv\", index = False)\n",
    "\n",
    "print('This cell was last run on: ')\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the interactive Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/visualization_demo.png\" alt=\"visualization_demo\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the cell below is executed, an interactive plot (as seen above) will open in your default browser. On the right 3 dropdown selectors enable you to choose of which model for which dataset and for which timestep the results should be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bokeh serve --show visualization.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop the interactive plot the kernel needs to be restarted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
